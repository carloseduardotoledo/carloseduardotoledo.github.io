---
layout: post
title: Big Data Risk Assessment
---

Lightbulb! When Professor Morelli introduced Graph Databases and Neo4j in MIT Big Data class last Saturday, an email exchange with my friend Robin about witch Big Data structure would make sense with Pipeline Risk Assessment just came into my mind.  At the time, we’ve mentioned Hadoop and MongoDB. But now I wonder if a Graph Database wouldn't be more suitable for the job.  Where else could I keep and interact with the pipeline network itself and the relationships of each pipe segment with exposures, mitigations and consequences?

![_config.yml]({{ site.baseurl }}/images/finger-3139200__340.jpg)

So, to be sure, I’ve decided start a three steps initiative:
1. Creating a tool to ETL into  Graph DB spatial features and topological relations;
1. Modeling the Pipeline Risk Assessment with Nodes and Edges;
1. Implementing a Graph based Risk Assessment algorithm.

The first step is already under development,  and I’m sharing it at [here](https://github.com/carloseduardotoledo/geo2graph). 

Obviously I’m not expecting Graph Databases to be the right tool for everything. An ecosystem of a complete solution would be a lot more diverse, for instance: I could use Hadoop and Apache Pig to crunch huge amounts of ILI to generate pipe segments, valves and anomalies.  ArcGIS Enterprise would be my choice to the main system of records and engagement. For transactional data like records of visits to households near the right of way a Relational or Document Database would be more suitable. Tempting as these others subjects are, I’ll try to keep my focus on the main initiative.

I’m keeping this blog ( [credits to Barry Clark](https://www.smashingmagazine.com/2014/08/build-blog-jekyll-github-pages/) ) to record this journey and I’m planning to have and update at every other week, so if you are interested stay tuned and feel free to contact me or to fork and contribute to the github project.

Best regards!
